<html>
<head>
<title>RecurrentJS Sentence Memorization Demo</title>

<style>
body {
  font-family: Arial, "Helvetica Neue", Helvetica, sans-serif;
  color: #333;
  padding: 20px;
}
#argmax {
  background-color: #DFD;
}
#ppl {
  color: #090;
  font-size: 20px;
}
#epoch {
  color: #900;
  font-size: 20px;
}
.apred {
  padding: 2px;
  margin: 5px;
  font-size: 14px;
}
#prepro_status {
  background-color: #FFD;
  padding: 5px;
}
#status {
  padding: 2px;
  margin-top: 5px;
}
#controls {
  margin: 5px;
}
.theslider {
  width:90%;
  display: inline-block;
}
.slider_value {
  width: 9%;
  display: inline-block;
}
#wrap {
  width: 800px;
  margin-right: auto;
  margin-left: auto;
  margin-bottom: 200px;
}
.abutton {
  width: 120px;
  height: 30px;
  margin: 10px 10px 10px 0px;
}
.hh {
  background-color: #EEE;
  padding: 5px;
  margin-top: 5px;
  border-bottom: 1px solid #999;
  margin-bottom: 2px;
}
#pplgraph {
  float: right;
}
#intro {
  text-align: justify;
}
</style>
<link href="external/jquery-ui.min.css" rel="stylesheet">

<script src="external/jquery-1.8.3.min.js"></script>
<script src="external/jquery-ui.min.js"></script>

<script src="src/recurrent.js"></script>
<script src="src/vis.js"></script>

<script type="text/javascript">

// prediction params
var sample_softmax_temperature = 1.0; // how peaky model predictions should be
var max_chars_gen = 1000;

// various global var inits
var epoch_size = -1;
var input_size = -1;
var output_size = -1;
var letterToIndex = {};
var indexToLetter = {};
var vocab = [];
var data_msgs = [];
var solver = new R.Solver(); // should be class because it needs memory for step caches
var pplGraph = new Rvis.Graph();

var model = {};

var utilAddToModel = function(modelto, modelfrom) {
  for(var k in modelfrom) {
    if(modelfrom.hasOwnProperty(k)) {
      // copy over the pointer but change the key to use the append
      modelto[k] = modelfrom[k];
    }
  }
}

var initModel = function() {
  // letter embedding vectors
  var model = {};
  model['Wil'] = new R.RandMat(input_size, letter_size , 0, 0.08);
  
  if(generator === 'rnn') {
    var rnn = R.initRNN(letter_size, hidden_sizes, output_size);
    utilAddToModel(model, rnn);
  } else {
    var lstm = R.initLSTM(letter_size, hidden_sizes, output_size);
    utilAddToModel(model, lstm);
  }

  return model;
}

var reinit_learning_rate_slider = function() {
  // init learning rate slider for controlling the decay
  // note that learning_rate is a global variable
  $("#lr_slider").slider({
    min: Math.log10(0.01) - 3.0,
    max: Math.log10(0.01) + 0.05,
    step: 0.05,
    value: Math.log10(learning_rate),
    slide: function( event, ui ) {
      learning_rate = Math.pow(10, ui.value);
      $("#lr_text").text(learning_rate.toFixed(5));
    }
  });
  $("#lr_text").text(learning_rate.toFixed(5));
}

var reinit = function(cb) {
  // note: reinit writes global vars
  
  // eval options to set some globals
  eval($("#newnet").val());

  reinit_learning_rate_slider();

  solver = new R.Solver(); // reinit solver
  pplGraph = new Rvis.Graph();

  ppl_list = [];
  tick_iter = 0;

  $.getJSON("data/conversations.json", function( data ) {
    data_msgs = data;
    console.log(data_msgs.length, data_msgs[0].length);
    initVocab(1); // takes count threshold for characters
    model = initModel();
    cb();
  });
}

var saveModelInternal = function() {
  var out = {};
  out['hidden_sizes'] = hidden_sizes;
  out['generator'] = generator;
  out['letter_size'] = letter_size;
  var model_out = {};
  for(var k in model) {
    if(model.hasOwnProperty(k)) {
      model_out[k] = model[k].toJSON();
    }
  }
  out['model'] = model_out;
  out['letterToIndex'] = letterToIndex;
  out['indexToLetter'] = indexToLetter;
  out['vocab'] = vocab;
  return out;
}

var saveSovlerInternal = function(){
  var solver_out = {};
  solver_out['decay_rate'] = solver.decay_rate;
  solver_out['smooth_eps'] = solver.smooth_eps;
  step_cache_out = {};
  for(var k in solver.step_cache) {
    if(solver.step_cache.hasOwnProperty(k)) {
      step_cache_out[k] = solver.step_cache[k].toJSON();
    }
  }
  solver_out['step_cache'] = step_cache_out;
  return solver_out;
}

var saveModel = function() {
  var obj = saveModelInternal();
  obj['solver'] = saveSovlerInternal();
  $("#tio").val(JSON.stringify(obj));
}

var loadModelInternal = function(j){
  hidden_sizes = j.hidden_sizes;
  generator = j.generator;
  letter_size = j.letter_size;
  model = {};
  for(var k in j.model) {
    if(j.model.hasOwnProperty(k)) {
      var matjson = j.model[k];
      model[k] = new R.Mat(1,1);
      model[k].fromJSON(matjson);
    }
  }
  letterToIndex = j['letterToIndex'];
  indexToLetter = j['indexToLetter'];
  vocab = j['vocab'];
}

var loadSolverInternal = function(j){
  solver = new R.Solver(); // have to reinit the solver since model changed
  solver.decay_rate = j.decay_rate;
  solver.smooth_eps = j.smooth_eps;
  solver.step_cache = {};
  for(var k in j.step_cache){
      if(j.step_cache.hasOwnProperty(k)){
          var matjson = j.step_cache[k];
          solver.step_cache[k] = new R.Mat(1,1);
          solver.step_cache[k].fromJSON(matjson);
      }
  }

}

var loadModel = function(j) {
  loadModelInternal(j);
  loadSolverInternal(j.solver);

  // Restart the graph
  pplGraph = new Rvis.Graph();
  // reinit these
  ppl_list = [];
  tick_iter = 0;
}

var forwardIndex = function(G, model, ix, prev) {
  var x = G.rowPluck(model['Wil'], ix);
  // forward prop the sequence learner
  if(generator === 'rnn') {
    var out_struct = R.forwardRNN(G, model, hidden_sizes, x, prev);
  } else {
    var out_struct = R.forwardLSTM(G, model, hidden_sizes, x, prev);
  }
  return out_struct;
}

function median(values) {
  values.sort( function(a,b) {return a - b;} );
  var half = Math.floor(values.length/2);
  if(values.length % 2) return values[half];
  else return (values[half-1] + values[half]) / 2.0;
}

var iid = null;
$(function() {

  // attach button handlers
  $('#learn').click(function(){ 
    reinit(function(){
      if(iid !== null) { clearInterval(iid); }
      iid = setInterval(tick, 0); 
    });
  });
  $('#stop').click(function(){ 
    if(iid !== null) { clearInterval(iid); }
    iid = null;
  });
  $("#resume").click(function(){
    if(iid === null) {
      iid = setInterval(tick, 0); 
    }
  });

  $("#savemodel").click(saveModel);
  $("#loadmodel").click(function(){
    var j = JSON.parse($("#tio").val());
    loadModel(j);
  });

  $("#loadpretrained").click(function(){
    $.getJSON("lstm_100_model.json", function(data) {
      pplGraph = new Rvis.Graph();
      learning_rate = 0.0001;
      reinit_learning_rate_slider();
      loadModel(data);
    });
  });

  //$('#gradcheck').click(gradCheck);

  $("#temperature_slider").slider({
    min: -1,
    max: 1.05,
    step: 0.05,
    value: 0,
    slide: function( event, ui ) {
      sample_softmax_temperature = Math.pow(10, ui.value);
      $("#temperature_text").text( sample_softmax_temperature.toFixed(2) );
    }
  });


  var workerload = 25;
  var t0 = +new Date();
  var noprocessed = 0;
  var ppl_list = [];

  var worker = new Worker("src/runner.js");
  var predictor = new Worker("src/runner.js");
  worker.addEventListener("message", function(e){
    switch(e.data.type){
      case "setup": $.getJSON("data/conversations.json", function( data ) {
                      data_msgs = data;
                      worker.postMessage({type: "setDataSet", data: data});
                      predictor.postMessage({type: "setDataSet", data: data});
                      console.log(data_msgs.length, data_msgs[0].length);
                    });
                    break;
      case "setDataSetDone": worker.postMessage({type: "calcVocab"});
                             break;
      case "calcVocabDone": eval($("#newnet").val());
                            reinit_learning_rate_slider();
                            solver = new R.Solver(); // reinit solver
                            
                            // Use results from calcVocab
                            console.log(e.data);
                            vocab=e.data.vocab;
                            input_size=e.data.input_size;
                            output_size=e.data.output_size;
                            epoch_size=e.data.epoch_size;
                            letterToIndex=e.data.letterToIndex;
                            indexToLetter=e.data.indexToLetter;
                            $("#prepro_status").text('found ' + vocab.length + ' distinct characters: ' + vocab.join(''));

                            model = initModel();
                            var ids = [];
                            for(var i=0;i<workerload;i++){
                             ids.push(R.randi(0, data_msgs.length));
                            }
                            console.log("ids", ids);
                            worker.postMessage({type: "process", model: saveModelInternal(), ids:ids});
                            break;
      case "processDone": // TODO
                          loadModelInternal(e.data.model);
                          var solver_stats = solver.step(model, learning_rate, regc, clipval);

                          var t1 = +new Date();
                          var tick_time = t1 - t0;
                          t0 = t1;
                          noprocessed += workerload;

                          // Send new process command so fancy displaying can be done in parallel
                          var ids = [];
                          for(var i=0;i<workerload;i++){
                           ids.push(R.randi(0, data_msgs.length));
                          }
                          console.log("ids", ids);
                          worker.postMessage({type: "process", model: saveModelInternal(), ids:ids});

                          // Run the predictor in a seperate thread
                          ids = [];
                          for(var i=0;i<5;i++){
                           ids.push(R.randi(0, data_msgs.length));
                          }
                          // do some predictions
                          predictor.postMessage({type: "predict", maxLength: max_chars_gen, model: saveModelInternal(), ids: ids, temperature: sample_softmax_temperature});


                          ppl_list = ppl_list.concat(e.data.ppls); 

                          // keep track of perplexity
                          $('#epoch').text('epoch: ' + (noprocessed/epoch_size).toFixed(3) + " ("+noprocessed+" conversations processed)");
                          $('#ppl').text('perplexity: ' + median(e.data.ppls).toFixed(2));
                          $('#ticktime').text('forw/bwd time per example: ' + (tick_time/workerload).toFixed(1) + 'ms');

                          break;
    }
  });

  predictor.addEventListener("message", function(e){
    switch(e.data.type){
      case "predictDone": $('#samples').html('');
                          for(var q=0;q<e.data.predictions.length;q++) {
                            var pred_div = '<div class="apred">Context: '+e.data.predictions[q].context+'<br>Output: '+e.data.predictions[q].output+'</div>'
                            $('#samples').append(pred_div);
                          }

                          // draw argmax prediction
                          $('#argmax').html('');
                          var pred_div = '<div class="apred">Context: '+e.data.argmax.context+'<br>Output: '+e.data.argmax.output+'</div>'
                          $('#argmax').append(pred_div);


                          if(noprocessed/workerload % 10 == 9){
                            var median_ppl = median(ppl_list);
                            ppl_list = [];
                            pplGraph.add(noprocessed, median_ppl);
                            pplGraph.drawSelf(document.getElementById("pplgraph"));
                          }
                          break;
    }
  });


  worker.postMessage({type: "ping"});


});

</script>
</head>

<body>
<a href="https://github.com/pci/recurrentjs"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"></a>


<div id="wrap">
  <h1>Deep Recurrent Nets conversation generation demo</h1>
 
  <div id="prepro_status"></div>

  <div class="hh">Controls/Options:</div>
  <button id="learn" class="abutton">learn/restart</button>
  <button id="resume" class="abutton">resume</button>
  <button id="stop" class="abutton">pause</button>
  <!-- <button id="gradcheck">gradcheck</button> -->
  <textarea id="newnet" style="width:100%; height:200px;">

// model parameters
generator = 'lstm'; // can be 'rnn' or 'lstm'
hidden_sizes = [100,100,100,100]; // list of sizes of hidden layers
letter_size = 7; // size of letter embeddings

// optimization
regc = 0.000001; // L2 regularization strength
learning_rate = 0.01; // learning rate
clipval = 5.0; // clip gradients at this value
  </textarea><br />
  protip: if your perplexity is exploding with Infinity try lowering the initial learning rate
  <br>
  <div id="status">

    <div>
      <div class="hh">Training stats:</div>
      <div class="aslider">
        <div class="slider_header">Learning rate: you want to anneal this over time if you're training for longer time.</div>
        <div class="theslider" id="lr_slider"></div>
        <div class="slider_value" id="lr_text"></div>
      </div>

      <canvas id="pplgraph"></canvas>
      <div id="ticktime"></div>
      <div id="gradclip"></div>
      <div id="epoch"></div>
      <div id="ppl"></div>

      <div style="clear:both;"></div>
    </div>

    <div class="hh">Model samples:</div>
    <div id="controls">
      <div class="aslider">
        <div class="slider_header">Softmax sample temperature: lower setting will generate more likely predictions, but you'll see more of the same common words again and again. Higher setting will generate less frequent words but you might see more spelling errors.</div>
        <div class="theslider" id="temperature_slider"></div>
        <div class="slider_value" id="temperature_text"></div>
      </div>
    </div>
    <div id="samples"></div>
    <div class="hh">Greedy argmax prediction:</div>
    <div id="argmax"></div>
  </div>
  <div id="io">
    <div class="hh">I/O save/load model JSON</div>

    <button id="savemodel" class="abutton">save model</button>
    <button id="loadmodel" class="abutton">load model</button>
    <div>
      You can save or load models with JSON using the textarea below.
    </div>
    <textarea style="width:100%; height:200px;" id="tio"></textarea>

    <br>
    <div class="hh">Pretrained model:</div>
    You can also choose to load an example pretrained model with the button below to see what the predictions look like in later stages. The pretrained model is an LSTM with one layer of 100 units, trained for ~10 hours. After clicking button below you should see the perplexity plummet to about 3.0, and see the predictions become better.<br>
    <button id="loadpretrained" class="abutton">load pretrained</button>

  </div>
</div>

</body>
</html>
